# Student-Performance-analysis-by-Machine-learning
Use of machine learning and data science makes life easier in every aspect, using machine learning and predicting the outcomes before the exam will allow the students as well as their parents and teachers to analyze the improvement area. we adopt numerous machine learning concepts and algorithms in order to predict the grades of the student before an exam. And machine learning is booming, and machine learning is firmly identified with (and frequently covers with) computational insights, which also focuses on prediction making through the use of technology. It has solid connections to numerical improvement, which conveys strategies, hypothesis and application areas to the field. Machine learning is some of the time conflated with data mining where the latter subfield concentrates more on exploratory information analysis and is known as supervised learning.
The main idea of this project is:
• In this project our aim is to analyze all the factors affecting the grades of a student and then predicting the grades of the student based upon those factors.
• We are implementing different supervised regression models for prediction of the grades.
• Using R-Squared, MAE, MSE, RMSE to evaluate the best model among all the
implemented supervised regression models.
• The outcome of the algorithms predicts the number of students who are likely to pass,
fail or promoted to next year. The results provide steps to improve the performance of the students who were predicted to fail or promoted.


Models:
Multiple Linear Regression: Multiple linear regression (MLR), also known simply as multiple regression, is a statistical technique that uses several explanatory variables to predict the outcome of a response variable. The goal of multiple linear regression (MLR) is to model the linear relationship between the explanatory (independent) variables and response (dependent) variable.
Support Vector Machine Regression: A support vector machine Regression is a supervised machine learning algorithm which is used in regression environment. In this calculation, we plot every data thing as a point in n- dimensional space (where n is number of highlights you have) with the estimation of each element being the estimation of a specific facilitate. At that point, we perform grouping by finding the hyper-plane that separate the two classes and form the best fit line and give up the predictions.
Random Forest Regression: A Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees
and a technique called Bootstrap Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees.
Logistic regression: Logistic regression is a classification model. The model builds a classification model to predict the probability that a given data entry belongs to the category numbered as “1” or “0”. Just like Linear regression assumes that the data follows a linear function, Logistic regression models the data using the sigmoid function.
XG Boost: XG Boost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) artificial neural networks tend to outperform all other algorithms or frameworks. However, when it comes to small- to-medium structured/tabular data, decision tree-based algorithms are considered best-in-class right now.
